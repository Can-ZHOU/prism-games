PRISM
=====

Version: 4.0.1.games
Date: Sat Oct 08 17:41:22 BST 2011
Hostname: qavbench.comlab
Command line: prism -ex examples/games/CDM/experiments/no_commit/cdm5032.smg examples/games/CDM/experiments/no_commit/props_recovery_from_3_N5.pctl -const 'Pexp=0.5,Q1=1.0,Q2=0.5,Q3=0.25,gamma=2.0,eta=1.0,lambda=1.0,k=70'

Parsing model file "examples/games/CDM/experiments/no_commit/cdm5032.smg"...

Parsing properties file "examples/games/CDM/experiments/no_commit/props_recovery_from_3_N5.pctl"...

10 properties:
(1) filter(range, <<[1]>> Pmax=? [ F<=k ((sched=1)&(<<[1]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
(2) filter(range, <<[1, 2]>> Pmax=? [ F<=k ((sched=1|sched=2)&(<<[1, 2]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
(3) filter(range, <<[1, 2, 3]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3)&(<<[1, 2, 3]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
(4) filter(range, <<[1, 2, 3, 4]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4)&(<<[1, 2, 3, 4]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
(5) filter(range, <<[1, 2, 3, 4, 5]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4|sched=5)&(<<[1, 2, 3, 4, 5]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
(6) filter(range, <<[1]>> Pmax=? [ F<=k ((sched=1)&(<<[1]>> R{"ntot1"}<10 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
(7) filter(range, <<[1, 2]>> Pmax=? [ F<=k ((sched=1|sched=2)&(<<[1, 2]>> R{"ntot12"}<20 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
(8) filter(range, <<[1, 2, 3]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3)&(<<[1, 2, 3]>> R{"ntot123"}<30 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
(9) filter(range, <<[1, 2, 3, 4]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4)&(<<[1, 2, 3, 4]>> R{"ntot1234"}<40 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
(10) filter(range, <<[1, 2, 3, 4, 5]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4|sched=5)&(<<[1, 2, 3, 4, 5]>> R{"ntot12345"}<50 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)

Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70

-------------------------------------------

Building model...

Computing reachable states...
 100032
Reachable states exploration and model construction done in 2.948 secs.
Sorting reachable states list...

Time for model construction: 3.167 seconds.

Type:        SMG

States:      100032 (1 initial)
Transitions: 843775
Choices:     255092
Max/avg:     3/2.55

-------------------------------------------

Model checking: filter(range, <<[1]>> Pmax=? [ F<=k ((sched=1)&(<<[1]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.015781433551386333,0.020322435742010533]

Time for model checking: 5.419 seconds.

Result: [0.015781433551386333,0.020322435742010533] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2]>> Pmax=? [ F<=k ((sched=1|sched=2)&(<<[1, 2]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.17924663467436713,0.21132667470223837]

Time for model checking: 5.604 seconds.

Result: [0.17924663467436713,0.21132667470223837] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3)&(<<[1, 2, 3]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.5210617306009082,0.57215525522974]

Time for model checking: 5.267 seconds.

Result: [0.5210617306009082,0.57215525522974] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3, 4]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4)&(<<[1, 2, 3, 4]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.8231866613519843,0.8630767465150719]

Time for model checking: 5.29 seconds.

Result: [0.8231866613519843,0.8630767465150719] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3, 4, 5]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4|sched=5)&(<<[1, 2, 3, 4, 5]>> P>0.9 [ F<=10 all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.9662071948805888,0.984313936543376]

Time for model checking: 5.645 seconds.

Result: [0.9662071948805888,0.984313936543376] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1]>> Pmax=? [ F<=k ((sched=1)&(<<[1]>> R{"ntot1"}<10 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70
Building reward structure...

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.3926720499439916,0.4136879971873711]

Time for model checking: 31.451 seconds.

Result: [0.3926720499439916,0.4136879971873711] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2]>> Pmax=? [ F<=k ((sched=1|sched=2)&(<<[1, 2]>> R{"ntot12"}<20 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70
Building reward structure...

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.772332242149764,0.7867456330667972]

Time for model checking: 41.687 seconds.

Result: [0.772332242149764,0.7867456330667972] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3)&(<<[1, 2, 3]>> R{"ntot123"}<30 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70
Building reward structure...

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.8704661466731931,0.8876952200323482]

Time for model checking: 70.612 seconds.

Result: [0.8704661466731931,0.8876952200323482] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3, 4]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4)&(<<[1, 2, 3, 4]>> R{"ntot1234"}<40 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70
Building reward structure...

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.8231866613519843,0.8630767465150719]

Time for model checking: 260.044 seconds.

Result: [0.8231866613519843,0.8630767465150719] (range of values over states satisfying filter)

-------------------------------------------

Model checking: filter(range, <<[1, 2, 3, 4, 5]>> Pmax=? [ F<=k ((sched=1|sched=2|sched=3|sched=4|sched=5)&(<<[1, 2, 3, 4, 5]>> R{"ntot12345"}<50 [ F all_prefer_1 ])) ], all_prefer_3&sched=0)
Model constants: Pexp=0.5,eta=1,gamma=2,lambda=1,Q1=1,Q2=0.5,Q3=0.25,k=70
Building reward structure...

States satisfying filter all_prefer_3&sched=0: 32

Range of values over states satisfying filter: [0.9662071948805888,0.984313936543376]

Time for model checking: 4.84 seconds.

Result: [0.9662071948805888,0.984313936543376] (range of values over states satisfying filter)

